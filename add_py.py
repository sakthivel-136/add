# -*- coding: utf-8 -*-
"""add.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TdTpgBxneyMo4aXVZhqlvvqltnuYOXDJ
"""

import streamlit as st
import pandas as pd
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import LabelEncoder
from sklearn.feature_extraction.text import TfidfVectorizer

# This must be the first Streamlit command
st.set_page_config(page_title="Kamaraj College FAQ Chatbot", layout="centered")

# Load model and data (caches for speed)
@st.cache_resource
def load_model_and_data():
    # Read the CSV from the local directory
    ques = pd.read_csv("kamaraj_college_faq.csv")
    ques.dropna(inplace=True)

    # Encode answers
    le = LabelEncoder()
    ques["Answer_Label"] = le.fit_transform(ques["Answer"])

    # Vectorize the questions
    vectorizer = TfidfVectorizer()
    X = vectorizer.fit_transform(ques["Question"])
    y = ques["Answer_Label"]

    # Train the model
    model = LogisticRegression()
    model.fit(X, y)

    return model, vectorizer, le

# Load everything once
model, vectorizer, label_encoder = load_model_and_data()

# Streamlit UI
st.title("üéì Kamaraj College FAQ Chatbot")
st.write("Ask any question related to **Kamaraj College of Engineering and Technology**:")

# User input
user_question = st.text_input("üí¨ Enter your question:")

# Handle input
if st.button("üîç Get Answer"):
    if user_question.strip() == "":
        st.warning("‚ö†Ô∏è Please enter a question.")
    else:
        vector = vectorizer.transform([user_question])
        prediction = model.predict(vector)[0]
        answer = label_encoder.inverse_transform([prediction])[0]
        st.success(f"üü¢ Answer: {answer}")